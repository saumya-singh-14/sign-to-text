# Sign-Language-to-text-coversion-using-Machine-learning
Problem Statement:<br />
The Sign Language-to-text conversion using Machine Learning project aims to develop an accurate and efficient system that can translate sign language gestures into written text. This project will address the communication gap between hearing-impaired people who use sign language and people who do not understand sign language. The system will be designed to recognize and translate the various signs and gestures used in sign language into textual representation.
To overcome the problem of Lack of communication between a deaf person and others who donâ€™t know sign language,  also the mood of the person cannot be detected through sign language. We proposed our software.<br />
Solution Description:<br />
Using TensorFlow to translate Sign Language in real-time. 
The project  purpose is to allow users to communicate more effectively with their computers and other people. To be specific, using this program, you can sign multiple words with one gesture and copy the translated text with the click of a button. Additionally, users can video call each other and talk using gestures that get converted into Computer Speech.<br />
Features<br />
1 Hand Gesture Training and Classification<br />
2 Prediction works in varying Lighting Conditions<br />
3 Retrainable Image Classes<br />
4 Translated Text can be Copied to Clipboard<br />
5 Cards that display Information about each Gesture<br />
6 Video Call functionality<br />
7 Text to Speech of translated text<br />
8 Minimal stress on memory<br />
9 Cohesive Text Styling<br />
10 Simple User Interface<br />
11 Comprehensive Commenting<br />
Hardware:<br />
Camera: A camera is used to capture the sign language gestures performed by the user.<br />
Microphone (optional): If you want to recognize spoken language as well, you can use a microphone to capture audio input.<br />
Processor: The hardware must be capable of running the software required for gesture recognition and processing.<br />
 Software:<br />
Image processing software: To detect and track the hand movements and gestures, image processing algorithms are used. These algorithms analyse the images from the camera and track the movement of the hand in real-time. OpenCV and python are mainly implimented.<br />
Machine learning software: Machine learning models are used to recognize the gestures performed by the user. These models are trained on large datasets of sign language gestures and can be customised for different languages or sign language dialects.<br />
Text-to-speech software: If you want the system to output spoken language as well, you can use text-to-speech software to convert the recognized text into spoken words.<br />
Live Sign Translator used from https://bit.ly/2CwPvgP<br />
OUTPUTS:<br />
![1](https://user-images.githubusercontent.com/110841948/230665521-74d87a34-b1d5-4b86-8ac3-05ca7560d366.jpeg)<br />
![2](https://user-images.githubusercontent.com/110841948/230665612-d868504d-e398-435b-a63a-5fb847f04cfb.jpeg)<br />
![3](https://user-images.githubusercontent.com/110841948/230665664-d4394802-bc62-4ee2-b947-6263b944c1d1.jpeg)<br />
![4](https://user-images.githubusercontent.com/110841948/230665678-116cea1c-15fe-4254-a476-c85e2028bb65.jpeg)<br />
![5](https://user-images.githubusercontent.com/110841948/230665698-097f74ba-2b85-41b0-abfb-cf8dda00e28f.jpeg)<br />



